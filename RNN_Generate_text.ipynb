{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": " RNN_Generate_text.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPbFQENI3nVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "import random\n",
        "import collections\n",
        "import time\n",
        "import nltk\n",
        "from nltk import sent_tokenize, word_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlf6N2kN58eL",
        "colab_type": "code",
        "outputId": "192e1b91-0ac8-40a5-f217-e2b8a67187b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbzj_xyt38Us",
        "colab_type": "code",
        "outputId": "0edde2ed-f709-41ad-ab2e-734238b85aa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bgxy0X83nVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(fname):\n",
        "    with open(fname) as f:\n",
        "        data = f.readlines()  \n",
        "    words = word_tokenize(str(data))\n",
        "    data = np.array(words)  \n",
        "    data = np.reshape(data, [-1, ])\n",
        "    return data\n",
        "\n",
        "train_file = 'alice_in_wonderland.txt'\n",
        "train_data = read_data(train_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSDk9MT-3nV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_dataset(train_data):\n",
        "    count = collections.Counter(train_data).most_common()\n",
        "    dictionary = dict()\n",
        "    for word, _ in count:\n",
        "        dictionary[word] = len(dictionary)\n",
        "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
        "    return dictionary, reverse_dictionary\n",
        "\n",
        "dictionary, reverse_dictionary = build_dataset(train_data)\n",
        "vocab_size = len(dictionary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnNJf6LS3nV3",
        "colab_type": "code",
        "outputId": "c2e1fc88-efff-4cf8-e1a1-8348e9a726be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "184"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMTKmLXq3nVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "training_iters = 50000\n",
        "display_step = 500\n",
        "n_input = 3\n",
        "\n",
        "# number of units in RNN cell\n",
        "n_hidden = 64\n",
        "rnn = tf.nn.rnn_cell\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHSNbQV83nV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey9Nocxb3nV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Place holder for Mini batch input output\n",
        "x = tf.placeholder(\"float\", [None, n_input,184])\n",
        "y = tf.placeholder(\"float\", [None, vocab_size])\n",
        "\n",
        "# RNN output node weights and biases\n",
        "weights = {\n",
        "    'out': tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
        "}\n",
        "biases = {\n",
        "    'out': tf.Variable(tf.random_normal([vocab_size]))\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdx4hbS83nWB",
        "colab_type": "code",
        "outputId": "34303f07-70d3-4509-944a-96c9210fa649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def input_one_hot(num):\n",
        "    x = np.zeros(vocab_size)\n",
        "    x[num] = 1 \n",
        "    return x.tolist()\n",
        "\n",
        "def RNN(x, weights, biases):\n",
        "    x = tf.unstack(x, n_input, 1)\n",
        "    print(np.shape(x))\n",
        "    ## 2 layered LSTM \n",
        "    rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden),rnn.BasicLSTMCell(n_hidden)])\n",
        "\n",
        "    # generate prediction\n",
        "    outputs, states = tf.nn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
        "\n",
        "    # there are n_input outputs but we only require the last output\n",
        "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
        "\n",
        "pred = RNN(x, weights, biases)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qek9ta1Q3nWE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss and optimizer\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
        "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "# Model evaluation\n",
        "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X07UH083nWG",
        "colab_type": "code",
        "outputId": "4c8bc2dd-46fc-4b00-ca87-a7233eb7f0c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Initializing the variables\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Launch the graph\n",
        "with tf.Session() as session:\n",
        "    session.run(init)\n",
        "    step = 0\n",
        "    offset = random.randint(0,n_input+1)\n",
        "    end_offset = n_input + 1\n",
        "    acc_total = 0\n",
        "    loss_total = 0\n",
        "\n",
        "    \n",
        "    while step < training_iters:\n",
        "        if offset > (len(train_data)-end_offset):\n",
        "            offset = random.randint(0, n_input+1)\n",
        "\n",
        "        symbols_in_keys = [ input_one_hot(dictionary[ str(train_data[i])]) for i in range(offset, offset+n_input) ]\n",
        "        symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input,vocab_size])\n",
        "        symbols_out_onehot = np.zeros([vocab_size], dtype=float)\n",
        "        symbols_out_onehot[dictionary[str(train_data[offset+n_input])]] = 1.0\n",
        "        symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n",
        "\n",
        "        _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], \\\n",
        "                                                feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n",
        "        loss_total += loss\n",
        "        acc_total += acc\n",
        "        \n",
        "        if (step+1) % display_step == 0:\n",
        "            print(\"Iter= \" + str(step+1) + \", Average Loss= \" + \\\n",
        "                  \"{:.6f}\".format(loss_total/display_step) + \", Average Accuracy= \" + \\\n",
        "                  \"{:.2f}%\".format(100*acc_total/display_step))\n",
        "            acc_total = 0\n",
        "            loss_total = 0\n",
        "            symbols_in = [train_data[i] for i in range(offset, offset + n_input)]\n",
        "            symbols_out = train_data[offset + n_input]\n",
        "            symbols_out_pred = reverse_dictionary[int(tf.argmax(onehot_pred, 1).eval())]\n",
        "            print(\"%s - Actual word:[%s] vs Predicted word:[%s]\" % (symbols_in,symbols_out,symbols_out_pred))\n",
        "        step += 1\n",
        "        offset += (n_input+1)\n",
        "    print(\"Optimization Finished!\")\n",
        "   \n",
        "    sentence = 'a very hopeful'\n",
        "    words = sentence.split(' ')\n",
        "    try:\n",
        "        symbols_in_keys = [ input_one_hot(dictionary[ str(train_data[i])]) for i in range(offset, offset+n_input) ]\n",
        "        for i in range(28):\n",
        "            keys = np.reshape(np.array(symbols_in_keys), [-1, n_input,vocab_size])\n",
        "            onehot_pred = session.run(pred, feed_dict={x: keys})\n",
        "            onehot_pred_index = int(tf.argmax(onehot_pred, 1).eval())\n",
        "            sentence = \"%s %s\" % (sentence,reverse_dictionary[onehot_pred_index])\n",
        "            symbols_in_keys = symbols_in_keys[1:]\n",
        "            symbols_in_keys.append(input_one_hot(onehot_pred_index))\n",
        "        print(sentence)\n",
        "    except:\n",
        "        print(\"Word not in dictionary\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter= 500, Average Loss= 5.352928, Average Accuracy= 2.20%\n",
            "['that', 'had', 'made'] - Actual word:[her] vs Predicted word:[,]\n",
            "Iter= 1000, Average Loss= 5.064784, Average Accuracy= 6.80%\n",
            "['pleased', 'at', 'having'] - Actual word:[found] vs Predicted word:[,]\n",
            "Iter= 1500, Average Loss= 4.603195, Average Accuracy= 7.60%\n",
            "['heard', 'her', 'voice'] - Actual word:[close] vs Predicted word:[,]\n",
            "Iter= 2000, Average Loss= 4.320282, Average Accuracy= 14.00%\n",
            "['Tut', ',', 'tut'] - Actual word:[,] vs Predicted word:[,]\n",
            "Iter= 2500, Average Loss= 3.410844, Average Accuracy= 26.00%\n",
            "['upon', 'Alice', \"'s\"] - Actual word:[shoulder] vs Predicted word:[much]\n",
            "Iter= 3000, Average Loss= 2.038906, Average Accuracy= 57.80%\n",
            "['together', '.', 'Alice'] - Actual word:[was] vs Predicted word:[was]\n",
            "Iter= 3500, Average Loss= 2.733498, Average Accuracy= 53.80%\n",
            "['kitchen', 'at', 'all'] - Actual word:[.] vs Predicted word:[']\n",
            "Iter= 4000, Average Loss= 3.709969, Average Accuracy= 22.20%\n",
            "['about', 'it', ','] - Actual word:[you] vs Predicted word:[you]\n",
            "Iter= 4500, Average Loss= 2.236672, Average Accuracy= 52.00%\n",
            "['.', \"'\", \"'\"] - Actual word:[Perhaps] vs Predicted word:[she]\n",
            "Iter= 5000, Average Loss= 2.022934, Average Accuracy= 53.00%\n",
            "['the', 'Duchess', 'was'] - Actual word:[very] vs Predicted word:[very]\n",
            "Iter= 5500, Average Loss= 1.532155, Average Accuracy= 65.00%\n",
            "['said', 'the', 'Duchess'] - Actual word:[,] vs Predicted word:[.]\n",
            "Iter= 6000, Average Loss= 1.606865, Average Accuracy= 63.00%\n",
            "['in', 'a', 'very'] - Actual word:[hopeful] vs Predicted word:[.]\n",
            "Iter= 6500, Average Loss= 1.385799, Average Accuracy= 69.00%\n",
            "['that', 'make', 'children'] - Actual word:[sweet-tempered] vs Predicted word:[sweet-tempered]\n",
            "Iter= 7000, Average Loss= 1.000339, Average Accuracy= 76.00%\n",
            "['makes', 'you', 'forget'] - Actual word:[to] vs Predicted word:[to]\n",
            "Iter= 7500, Average Loss= 0.597129, Average Accuracy= 86.00%\n",
            "['squeezed', 'herself', 'up'] - Actual word:[closer] vs Predicted word:[closer]\n",
            "Iter= 8000, Average Loss= 0.221526, Average Accuracy= 94.00%\n",
            "['it', 'as', 'well'] - Actual word:[as] vs Predicted word:[as]\n",
            "Iter= 8500, Average Loss= 0.602033, Average Accuracy= 85.80%\n",
            "['savage', 'when', 'they'] - Actual word:[met] vs Predicted word:[met]\n",
            "Iter= 9000, Average Loss= 0.996408, Average Accuracy= 77.40%\n",
            "['of', 'rule', ','] - Actual word:['] vs Predicted word:[']\n",
            "Iter= 9500, Average Loss= 0.272041, Average Accuracy= 93.80%\n",
            "[\"''\", ',', '``'] - Actual word:[ear] vs Predicted word:[ear]\n",
            "Iter= 10000, Average Loss= 0.697270, Average Accuracy= 84.00%\n",
            "['Everything', \"'s\", 'got'] - Actual word:[a] vs Predicted word:[a]\n",
            "Iter= 10500, Average Loss= 0.608688, Average Accuracy= 85.60%\n",
            "[\"'s\", 'shoulder', ','] - Actual word:[and] vs Predicted word:[and]\n",
            "Iter= 11000, Average Loss= 0.135018, Average Accuracy= 96.40%\n",
            "['together', '.', 'Alice'] - Actual word:[was] vs Predicted word:[was]\n",
            "Iter= 11500, Average Loss= 0.396938, Average Accuracy= 90.80%\n",
            "['well', 'without', '—'] - Actual word:[Maybe] vs Predicted word:[Maybe]\n",
            "Iter= 12000, Average Loss= 0.421880, Average Accuracy= 90.00%\n",
            "['about', 'it', ','] - Actual word:[you] vs Predicted word:[you]\n",
            "Iter= 12500, Average Loss= 0.183971, Average Accuracy= 94.80%\n",
            "['a', 'bit', '.'] - Actual word:['] vs Predicted word:[']\n",
            "Iter= 13000, Average Loss= 0.711844, Average Accuracy= 83.00%\n",
            "['because', 'the', 'Duchess'] - Actual word:[was] vs Predicted word:[was]\n",
            "Iter= 13500, Average Loss= 0.290517, Average Accuracy= 93.60%\n",
            "['you', 'dear', 'old'] - Actual word:[thing] vs Predicted word:[thing]\n",
            "Iter= 14000, Average Loss= 0.009246, Average Accuracy= 100.00%\n",
            "['(', 'not', 'in'] - Actual word:[a] vs Predicted word:[a]\n",
            "Iter= 14500, Average Loss= 0.082360, Average Accuracy= 97.80%\n",
            "['bitter', '—', 'and'] - Actual word:[—] vs Predicted word:[—]\n",
            "Iter= 15000, Average Loss= 0.341442, Average Accuracy= 92.00%\n",
            "['makes', 'you', 'forget'] - Actual word:[to] vs Predicted word:[to]\n",
            "Iter= 15500, Average Loss= 0.247459, Average Accuracy= 94.40%\n",
            "['up', 'closer', 'to'] - Actual word:[Alice] vs Predicted word:[Alice]\n",
            "Iter= 16000, Average Loss= 0.140560, Average Accuracy= 96.60%\n",
            "[\"'\", 'You', 'ca'] - Actual word:[n't] vs Predicted word:[n't]\n",
            "Iter= 16500, Average Loss= 0.159673, Average Accuracy= 96.80%\n",
            "['in', 'the', 'kitchen'] - Actual word:[.] vs Predicted word:[.]\n",
            "Iter= 17000, Average Loss= 0.142466, Average Accuracy= 96.00%\n",
            "['rule', ',', \"'\"] - Actual word:[and] vs Predicted word:[and]\n",
            "Iter= 17500, Average Loss= 0.110107, Average Accuracy= 97.40%\n",
            "['``', 'ear', '.'] - Actual word:['] vs Predicted word:[']\n",
            "Iter= 18000, Average Loss= 0.108651, Average Accuracy= 97.00%\n",
            "[\"'s\", 'got', 'a'] - Actual word:[moral] vs Predicted word:[moral]\n",
            "Iter= 18500, Average Loss= 0.081107, Average Accuracy= 98.20%\n",
            "['However', ',', 'she'] - Actual word:[did] vs Predicted word:[did]\n",
            "Iter= 19000, Average Loss= 0.057132, Average Accuracy= 99.00%\n",
            "['the', 'pepper', 'that'] - Actual word:[had] vs Predicted word:[had]\n",
            "Iter= 19500, Average Loss= 0.108090, Average Accuracy= 96.80%\n",
            "[',', 'very', 'much'] - Actual word:[pleased] vs Predicted word:[pleased]\n",
            "Iter= 20000, Average Loss= 0.089344, Average Accuracy= 97.40%\n",
            "['little', 'startled', 'when'] - Actual word:[she] vs Predicted word:[she]\n",
            "Iter= 20500, Average Loss= 0.021687, Average Accuracy= 99.40%\n",
            "['.', \"'\", 'Tut'] - Actual word:[,] vs Predicted word:[,]\n",
            "Iter= 21000, Average Loss= 0.060821, Average Accuracy= 98.40%\n",
            "['chin', 'upon', 'Alice'] - Actual word:['s] vs Predicted word:['s]\n",
            "Iter= 21500, Average Loss= 0.012451, Average Accuracy= 99.40%\n",
            "['.', 'Alice', 'was'] - Actual word:[very] vs Predicted word:[very]\n",
            "Iter= 22000, Average Loss= 0.171350, Average Accuracy= 96.20%\n",
            "['very', 'well', 'without'] - Actual word:[—] vs Predicted word:[—]\n",
            "Iter= 22500, Average Loss= 0.102259, Average Accuracy= 98.00%\n",
            "['it', ',', 'you'] - Actual word:[know] vs Predicted word:[know]\n",
            "Iter= 23000, Average Loss= 0.035207, Average Accuracy= 98.20%\n",
            "['in', 'a', 'bit'] - Actual word:[.] vs Predicted word:[.]\n",
            "Iter= 23500, Average Loss= 0.067554, Average Accuracy= 98.40%\n",
            "[',', 'because', 'the'] - Actual word:[Duchess] vs Predicted word:[Duchess]\n",
            "Iter= 24000, Average Loss= 0.074439, Average Accuracy= 98.60%\n",
            "['said', 'the', 'Duchess'] - Actual word:[,] vs Predicted word:[.]\n",
            "Iter= 24500, Average Loss= 0.040742, Average Accuracy= 99.00%\n",
            "['to', 'herself', ','] - Actual word:[(] vs Predicted word:[(]\n",
            "Iter= 25000, Average Loss= 0.064667, Average Accuracy= 98.60%\n",
            "['that', 'makes', 'them'] - Actual word:[bitter] vs Predicted word:[sour]\n",
            "Iter= 25500, Average Loss= 0.029435, Average Accuracy= 99.00%\n",
            "[',', 'and', 'that'] - Actual word:[makes] vs Predicted word:[makes]\n",
            "Iter= 26000, Average Loss= 0.004304, Average Accuracy= 100.00%\n",
            "['you', 'can', 'find'] - Actual word:[it] vs Predicted word:[it]\n",
            "Iter= 26500, Average Loss= 0.025102, Average Accuracy= 99.00%\n",
            "['sharp', 'chin', '.'] - Actual word:[However] vs Predicted word:[However]\n",
            "Iter= 27000, Average Loss= 0.088332, Average Accuracy= 98.20%\n",
            "[',', 'and', 'thought'] - Actual word:[to] vs Predicted word:[to]\n",
            "Iter= 27500, Average Loss= 0.057094, Average Accuracy= 98.60%\n",
            "['always', 'pepper', 'that'] - Actual word:[makes] vs Predicted word:[makes]\n",
            "Iter= 28000, Average Loss= 0.044594, Average Accuracy= 99.00%\n",
            "[\"'She\", 'had', 'quite'] - Actual word:[forgotten] vs Predicted word:[forgotten]\n",
            "Iter= 28500, Average Loss= 0.053338, Average Accuracy= 98.40%\n",
            "[',', \"'\", 'Alice'] - Actual word:[ventured] vs Predicted word:[ventured]\n",
            "Iter= 29000, Average Loss= 0.032821, Average Accuracy= 99.20%\n",
            "['she', 'was', 'exactly'] - Actual word:[the] vs Predicted word:[the]\n",
            "Iter= 29500, Average Loss= 0.052645, Average Accuracy= 99.00%\n",
            "[',', 'and', 'they'] - Actual word:[walked] vs Predicted word:[walked]\n",
            "Iter= 30000, Average Loss= 0.023969, Average Accuracy= 99.60%\n",
            "['my', 'kitchen', 'at'] - Actual word:[all] vs Predicted word:[all]\n",
            "Iter= 30500, Average Loss= 0.024077, Average Accuracy= 99.40%\n",
            "[\"n't\", 'be', 'so'] - Actual word:[stingy] vs Predicted word:[stingy]\n",
            "Iter= 31000, Average Loss= 0.059226, Average Accuracy= 99.20%\n",
            "['in', 'a', 'bit'] - Actual word:[.] vs Predicted word:[.]\n",
            "Iter= 31500, Average Loss= 0.049632, Average Accuracy= 98.80%\n",
            "[';', 'and', 'secondly'] - Actual word:[,] vs Predicted word:[,]\n",
            "Iter= 32000, Average Loss= 0.015919, Average Accuracy= 99.80%\n",
            "['she', 'tucked', 'her'] - Actual word:[arm] vs Predicted word:[arm]\n",
            "Iter= 32500, Average Loss= 0.041245, Average Accuracy= 99.40%\n",
            "['I', 'wo', \"n't\"] - Actual word:[have] vs Predicted word:[have]\n",
            "Iter= 33000, Average Loss= 0.039301, Average Accuracy= 99.20%\n",
            "['that', 'make', 'children'] - Actual word:[sweet-tempered] vs Predicted word:[sweet-tempered]\n",
            "Iter= 33500, Average Loss= 0.042383, Average Accuracy= 99.40%\n",
            "['forget', 'to', 'talk'] - Actual word:[.] vs Predicted word:[.]\n",
            "Iter= 34000, Average Loss= 0.018273, Average Accuracy= 99.20%\n",
            "['side', 'as', 'she'] - Actual word:[spoke] vs Predicted word:[spoke]\n",
            "Iter= 34500, Average Loss= 0.021135, Average Accuracy= 99.60%\n",
            "['[', '``', \"'\"] - Actual word:[You] vs Predicted word:[You]\n",
            "Iter= 35000, Average Loss= 0.001497, Average Accuracy= 100.00%\n",
            "['it', 'was', 'only'] - Actual word:[the] vs Predicted word:[the]\n",
            "Iter= 35500, Average Loss= 0.000114, Average Accuracy= 100.00%\n",
            "['people', 'hot-tempered', ','] - Actual word:['] vs Predicted word:[']\n",
            "Iter= 36000, Average Loss= 0.033147, Average Accuracy= 99.60%\n",
            "[',', 'you', 'know'] - Actual word:[—] vs Predicted word:[—]\n",
            "Iter= 36500, Average Loss= 0.048205, Average Accuracy= 99.40%\n",
            "[\"'\", 'Perhaps', 'it'] - Actual word:[has] vs Predicted word:[has]\n",
            "Iter= 37000, Average Loss= 0.016329, Average Accuracy= 99.60%\n",
            "['and', 'secondly', ','] - Actual word:[because] vs Predicted word:[because]\n",
            "Iter= 37500, Average Loss= 0.020054, Average Accuracy= 99.60%\n",
            "[\"'\", 'said', 'the'] - Actual word:[Duchess] vs Predicted word:[Duchess]\n",
            "Iter= 38000, Average Loss= 0.087540, Average Accuracy= 98.60%\n",
            "['hopeful', 'tone', 'though'] - Actual word:[)] vs Predicted word:[)]\n",
            "Iter= 38500, Average Loss= 0.043554, Average Accuracy= 99.00%\n",
            "['children', 'sweet-tempered', '.'] - Actual word:[I] vs Predicted word:[I]\n",
            "Iter= 39000, Average Loss= 0.032467, Average Accuracy= 99.00%\n",
            "['ca', \"n't\", 'tell'] - Actual word:[you] vs Predicted word:[you]\n",
            "Iter= 39500, Average Loss= 0.020410, Average Accuracy= 99.20%\n",
            "['like', 'keeping', 'so'] - Actual word:[close] vs Predicted word:[close]\n",
            "Iter= 40000, Average Loss= 0.001116, Average Accuracy= 100.00%\n",
            "['could', '.', '``'] - Actual word:[]] vs Predicted word:[]]\n",
            "Iter= 40500, Average Loss= 0.051112, Average Accuracy= 99.40%\n",
            "['they', 'met', 'in'] - Actual word:[the] vs Predicted word:[the]\n",
            "Iter= 41000, Average Loss= 0.003542, Average Accuracy= 99.80%\n",
            "[',', \"'\", 'and'] - Actual word:[vinegar] vs Predicted word:[vinegar]\n",
            "Iter= 41500, Average Loss= 0.073313, Average Accuracy= 98.80%\n",
            "['her\\\\n', \"''\", ','] - Actual word:[``] vs Predicted word:[``]\n",
            "Iter= 42000, Average Loss= 0.046922, Average Accuracy= 99.20%\n",
            "['said', 'the', 'Duchess'] - Actual word:[.] vs Predicted word:[,]\n",
            "Iter= 42500, Average Loss= 0.037030, Average Accuracy= 99.60%\n",
            "['and', 'it', 'was'] - Actual word:[an] vs Predicted word:[an]\n",
            "Iter= 43000, Average Loss= 0.061443, Average Accuracy= 98.60%\n",
            "[',', 'and', 'thought'] - Actual word:[to] vs Predicted word:[to]\n",
            "Iter= 43500, Average Loss= 0.010023, Average Accuracy= 99.80%\n",
            "[\"'s\", 'always', 'pepper'] - Actual word:[that] vs Predicted word:[that]\n",
            "Iter= 44000, Average Loss= 0.019648, Average Accuracy= 99.60%\n",
            "[',', 'you', 'know'] - Actual word:[—] vs Predicted word:[—]\n",
            "Iter= 44500, Average Loss= 0.047568, Average Accuracy= 99.20%\n",
            "['Perhaps', 'it', 'has'] - Actual word:[n't] vs Predicted word:[n't]\n",
            "Iter= 45000, Average Loss= 0.028253, Average Accuracy= 99.20%\n",
            "[',', 'because', 'she'] - Actual word:[was] vs Predicted word:[was]\n",
            "Iter= 45500, Average Loss= 0.070641, Average Accuracy= 99.00%\n",
            "['tucked', 'her', 'arm'] - Actual word:[affectionately] vs Predicted word:[affectionately]\n",
            "Iter= 46000, Average Loss= 0.011249, Average Accuracy= 99.60%\n",
            "[')', ',', \"'\"] - Actual word:[I] vs Predicted word:[I]\n",
            "Iter= 46500, Average Loss= 0.029448, Average Accuracy= 99.60%\n",
            "['and', 'such', 'things'] - Actual word:[that] vs Predicted word:[that]\n",
            "Iter= 47000, Average Loss= 0.021608, Average Accuracy= 99.20%\n",
            "['I', 'ca', \"n't\"] - Actual word:[tell] vs Predicted word:[tell]\n",
            "Iter= 47500, Average Loss= 0.064557, Average Accuracy= 99.00%\n",
            "['she', 'spoke', '.'] - Actual word:[Alice] vs Predicted word:[Alice]\n",
            "Iter= 48000, Average Loss= 0.069618, Average Accuracy= 99.00%\n",
            "['see', 'you', 'again'] - Actual word:[,] vs Predicted word:[,]\n",
            "Iter= 48500, Average Loss= 0.005997, Average Accuracy= 99.80%\n",
            "[\"'m\", 'a', 'Duchess'] - Actual word:[,] vs Predicted word:[,]\n",
            "Iter= 49000, Average Loss= 0.062428, Average Accuracy= 99.00%\n",
            "['—', 'and', 'camomile'] - Actual word:[that] vs Predicted word:[that]\n",
            "Iter= 49500, Average Loss= 0.050135, Average Accuracy= 99.00%\n",
            "['dear', ',', 'and'] - Actual word:[that] vs Predicted word:[that]\n",
            "Iter= 50000, Average Loss= 0.032999, Average Accuracy= 99.60%\n",
            "['.', \"'\", 'And'] - Actual word:[she] vs Predicted word:[she]\n",
            "Optimization Finished!\n",
            "a very hopeful closer to Alice 's side as she spoke . Alice did not much like keeping so close to her : first , because the Duchess was very ugly\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APAuNHPp3nWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}